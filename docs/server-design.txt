===================================================================================================
Threading model

Brian: is a server going to have one threadservicing all caches/cached items or one thread per cache/cached items

----------------------------------------------------------------------------------------------------

There will be several threads... but as few as possible.

The network communications are event based, and that would be on the main thread.  When it gets data, it will add it to 
a pipeline queue, which will just be an array.

I was thinking of having two threads for processing, handling client requests.  But only one at a time will actually be 
accessing the data.  The threads processing data will rotate in a round-robin so that servicing requests remain in the 
order received.

The process for each 'working' thread would be:
 1.   parse the data from the request.
 2.   look up the data in the b-tree and get the value from the chunk.
 3.   build the reply.
 4.   add the reply to the output buffer for the client.

The main thread would then use its event based system to then send out data to the client.

Then we would need to handle passing updates to the backup servers for the buckets.  I haven't decided whether to have 
one of those for each bucket, or one overall.

There would be a couple of other threads, done as needed.  Because we want as little as possible to block the main 
thread (for network handling) and the processing threads.

But there is nothing in the server-design so far the 'requires' threads.   So I'll keep in mind that we'll be using 
threads, but at first I'll write it as single-threaded and do everything in sequence.  The advantage of this is that it 
can be vastly easier to debug.  So in the early stages, when getting other parts of the system working well, I'll have 
the server running with only a main thread, with everything triggered by network events.




